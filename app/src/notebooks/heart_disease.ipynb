{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Heart Disease Prediction Notebook"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In this notebook we will develop a method to predict heart disease from the heart disease dataset in the UCI Machine Learning repository."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Importing libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## Reading data and checking structure"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "source": [
    "Here is a bit more fleshed out description of each variable:\n",
    "\n",
    "1. **age**: The person's age in years\n",
    "2. **sex**: The person's sex (1 = male, 0 = female)\n",
    "3. **cp**: The chest pain experienced (Value 1: typical angina, Value 2: atypical angina, Value 3: non-anginal pain, Value 4: asymptomatic)\n",
    "4. **trestbps**: The person's resting blood pressure (mm Hg on admission to the hospital)\n",
    "5. **chol**: The person's cholesterol measurement in mg/dl\n",
    "6. **bs**: The person's fasting blood sugar (> 120 mg/dl, 1 = true; 0 = false)\n",
    "7. **restecg**: Resting electrocardiographic measurement (0 = normal, 1 = having ST-T wave abnormality, 2 = showing probable or definite left ventricular hypertrophy by Estes' criteria)\n",
    "8. **thalach**: The person's maximum heart rate achieved\n",
    "9. **exang**: Exercise induced angina (1 = yes; 0 = no)\n",
    "10. **oldpeak**: ST depression induced by exercise relative to rest ('ST' relates to positions on the ECG plot.)\n",
    "11. **slope**: the slope of the peak exercise ST segment (Value 1: upsloping, Value 2: flat, Value 3: downsloping)\n",
    "12. **ca**: The number of major vessels (0-3)\n",
    "13. **thal**: A blood disorder called thalassemia (3 = normal; 6 = fixed defect; 7 = reversable defect)\n",
    "14. **target**: Heart disease (0 = no, 1 = yes)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Feature Engineering and Data Cleaning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Let's try to clean the column names of the data. If we name our columns properly, we will avoid confusion in the future during data cleaning or engineering new features."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing column names\n",
    "df.columns = ['age', 'sex', 'chest_pain_type', 'resting_blood_pressure', 'cholesterol', 'fasting_blood_sugar', 'rest_ecg', 'max_heart_rate_achieved',\n",
    "       'exercise_induced_angina', 'st_depression', 'st_slope', 'num_major_vessels', 'thalassemia', 'target']"
   ]
  },
  {
   "source": [
    "We see that a lot of the features that are supposed to be categorical are in fact encoded as integers. Let's try to clean these up. \n",
    "\n",
    "By doing this, we can set up our data for visualizing as well as providing as good foundation for data preprocessing for training models."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Function will be used to clean the dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "        A dataframe containing the the heart disease data.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df: DataFrame\n",
    "        A dataframe containing the cleansed heart disease data.\n",
    "    \"\"\"\n",
    "    df['sex'][df['sex'] == 0] = 'female'\n",
    "    df['sex'][df['sex'] == 1] = 'male'\n",
    "\n",
    "    df['chest_pain_type'][df['chest_pain_type'] == 0] = 'typical angina'\n",
    "    df['chest_pain_type'][df['chest_pain_type'] == 1] = 'atypical angina'\n",
    "    df['chest_pain_type'][df['chest_pain_type'] == 2] = 'non-anginal pain'\n",
    "    df['chest_pain_type'][df['chest_pain_type'] == 3] = 'asymptomatic'\n",
    "\n",
    "    df['fasting_blood_sugar'][df['fasting_blood_sugar'] == 0] = 'lower than 120mg/ml'\n",
    "    df['fasting_blood_sugar'][df['fasting_blood_sugar'] == 1] = 'greater than 120mg/ml'\n",
    "\n",
    "    df['rest_ecg'][df['rest_ecg'] == 0] = 'normal'\n",
    "    df['rest_ecg'][df['rest_ecg'] == 1] = 'ST-T wave abnormality'\n",
    "    df['rest_ecg'][df['rest_ecg'] == 2] = 'left ventricular hypertrophy'\n",
    "\n",
    "    df['exercise_induced_angina'][df['exercise_induced_angina'] == 0] = 'no'\n",
    "    df['exercise_induced_angina'][df['exercise_induced_angina'] == 1] = 'yes'\n",
    "\n",
    "    df['st_slope'][df['st_slope'] == 0] = 'upsloping'\n",
    "    df['st_slope'][df['st_slope'] == 1] = 'flat'\n",
    "    df['st_slope'][df['st_slope'] == 2] = 'downsloping'\n",
    "\n",
    "    df['thalassemia'][df['thalassemia'] == 0] = 'normal'\n",
    "    df['thalassemia'][df['thalassemia'] == 1] = 'fixed defect'\n",
    "    df['thalassemia'][df['thalassemia'] == 2] = 'reversable defect'\n",
    "    df['thalassemia'][df['thalassemia'] == 3] = 'reversable defect'\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dtypes(df):\n",
    "    \"\"\"\n",
    "    Function will be used to convert features to appropriate type.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "        A dataframe containing the heart disease data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df: DataFrame\n",
    "        A dataframe containing the cleansed heart disease data.\n",
    "    \"\"\"\n",
    "    df['sex'] = df['sex'].astype('object')\n",
    "    df['chest_pain_type'] = df['chest_pain_type'].astype('object')\n",
    "    df['fasting_blood_sugar'] = df['fasting_blood_sugar'].astype('object')\n",
    "    df['rest_ecg'] = df['rest_ecg'].astype('object')\n",
    "    df['exercise_induced_angina'] = df['exercise_induced_angina'].astype('object')\n",
    "    df['st_slope'] = df['st_slope'].astype('object')\n",
    "    df['thalassemia'] = df['thalassemia'].astype('object')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_data(df)\n",
    "df = change_dtypes(df)"
   ]
  },
  {
   "source": [
    "## Correlations between features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Let's try to see how our features are correlated with each other as well as the target variable."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly figure for creating correlation:\n",
    "fig = go.Figure(data=go.Heatmap(z=df.corr(), \n",
    "                                x=df.corr().columns, \n",
    "                                y=df.corr().columns, \n",
    "                                colorscale=px.colors.sequential.Blugrn, \n",
    "                                text=df.corr().values, \n",
    "                               ))\n",
    "\n",
    "# Updating the dimensions and title:\n",
    "fig.update_layout(height=600, \n",
    "                  width=600, \n",
    "                  title=\"Correlation Matrix Heatmap\")\n",
    "fig.show()"
   ]
  },
  {
   "source": [
    "There seems to be weak to moderate correlations between the features. Therefore, we can retain all of the features for the purpose of traning."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Visualizing our features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "This section will have visualizations which will be created automatically\n",
    "        based on rules assigned for the type of variable being visualized. \n",
    "\n",
    "Rules for single variable visualizations:\n",
    "* Numerical variables will be represented by histograms.\n",
    "* The visualizations for numerical variables will have \"Frequency\" as the y-axis label.\n",
    "* Categorical variables will be represented by bar charts.\n",
    "* The visualizations for categorical variables will have \"Count\" as the y-axis label. \n",
    "            "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_feature(df, feature):\n",
    "    \"\"\"\n",
    "    This function will be used to plot a single feature.\n",
    "\n",
    "    Every feature's type will be first evaluated and then the\n",
    "    feature's distribution will be graphed accordingly.\n",
    "\n",
    "    Rules for single variable visualizations:\n",
    "    * Numerical variables will be represented by histograms.\n",
    "    * The visualizations for numerical variables will have \"Frequency\" as the y-axis label.\n",
    "    * Categorical variables will be represented by bar charts.\n",
    "    * The visualizations for categorical variables will have \"Count\" as the y-axis label. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "        A dataframe containing the heart disease data.\n",
    "        \n",
    "    feature: str\n",
    "        The feature whose data needs to be plotted.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    fig = None\n",
    "    xaxis_type=None\n",
    "    yaxis_title=\"\"\n",
    "\n",
    "    # Switching int features with low cardinality to object:\n",
    "    df[\"num_major_vessels\"] = df[\"num_major_vessels\"].astype(\"object\")\n",
    "    df[\"target\"] = df[\"target\"].astype(\"object\")\n",
    "    # Check feature type and plot appropriately:\n",
    "    if df[feature].dtype == 'int64' or df[feature].dtype == 'float64':\n",
    "        #TODO(Sayar) Add slider widget here:\n",
    "        fig = px.histogram(x=df[feature].values, nbins=0)\n",
    "\n",
    "        yaxis_title = \"Frequency\"\n",
    "\n",
    "    elif df[feature].dtype == 'object':\n",
    "        fig = px.bar(y=df[feature].value_counts(), \n",
    "                     x=df[feature].value_counts().index.astype(str), \n",
    "                     color=df[feature].value_counts().index.astype(str), \n",
    "                     text=df[feature].value_counts())\n",
    "\n",
    "        xaxis_type = \"category\"\n",
    "        yaxis_title = \"Count\"\n",
    "\n",
    "    fig.update_xaxes(title=feature)\n",
    "    fig.update_yaxes(title=yaxis_title)\n",
    "    fig.update_layout(showlegend=False, \n",
    "                      title=\"Distribution of {}\".format(feature), \n",
    "                      xaxis_type=xaxis_type)\n",
    "    fig.show()\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterating over every feature and plotting it:\n",
    "for feature in df.columns:\n",
    "    plot_single_feature(df, feature)"
   ]
  },
  {
   "source": [
    "We would also like to plot interactions between two features to understand the relationship between them. Let's try to do this. We can again leverage writing a function to make things easier for us to do.\n",
    "\n",
    "Feature interaction visualizations will have two variables and will plot the relationship between them.\n",
    "\n",
    "Rules for feature interaction visualization:\n",
    "* Only two variables can be used for this visualization.\n",
    "* Both variables have to be different.\n",
    "* For numerical vs numerical visuals, we will be using scatter plots.\n",
    "* For numerical vs categorical visuals, we will be using box plots.\n",
    "* For categorical vs categorical visuals, we will be using scatter plots."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_numerical_numerical(df, feature_1, feature_2):\n",
    "    \"\"\"Plots numerical vs numerical features\"\"\"\n",
    "    fig = px.scatter(df, feature_1, feature_2)\n",
    "    fig.update_layout(title=\"Plot of {} vs. {}\".format(feature_1, \n",
    "                                                       feature_2))\n",
    "    fig.show()\n",
    "\n",
    "def plot_numerical_categorical(df, feature_1, feature_2):\n",
    "    \"\"\"Plots numerical vs categorical features\"\"\"\n",
    "    x_var, y_var = feature_1, feature_2\n",
    "    # feature_1 is passed into x_var. If it is not categorical, \n",
    "    # we switch it with y_var:\n",
    "    if df[feature_1].dtypes == \"int64\" or df[feature_1].dtypes == \"float64\":\n",
    "        x_var,y_var = y_var,x_var\n",
    "\n",
    "    fig = px.box(df, \n",
    "                 x=x_var, \n",
    "                 y=y_var, \n",
    "                 color=x_var)\n",
    "                 \n",
    "    fig.update_layout(title=\"Plot of {} vs. {}\".format(x_var, y_var))\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "def plot_categorical_categorical(df, feature_1, feature_2):\n",
    "    \"\"\"Plots categorical vs categorical features\"\"\"\n",
    "    fig = px.parallel_categories(df, \n",
    "                                 dimensions=[feature_1, feature_2], \n",
    "                                 )\n",
    "    fig.update_layout(title=\"Plot of {} vs. {}\".format(feature_1, feature_2))\n",
    "    fig.show()\n",
    "\n",
    "def plot_dual_features(df, feature_1, feature_2):\n",
    "    \"\"\"\n",
    "    This function will be used to plot feature interactions between\n",
    "    two features.\n",
    "\n",
    "    Rules for feature interaction visualization:\n",
    "\n",
    "    * Only two variables can be used for this visualization.\n",
    "    * Both variables have to be different.\n",
    "    * For numerical vs numerical visuals, we will be using scatter plots.\n",
    "    * For numerical vs categorical visuals, we will be using box plots.\n",
    "    * For categorical vs categorical visuals, we will be using scatter plots.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "        A dataframe containing the heart disease data.\n",
    "    \n",
    "    feature_1: str\n",
    "        The first feature to be used in the plot.\n",
    "\n",
    "    feature_2: str\n",
    "        The second feature to be used in the plot.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Cannot allow same feature plots:\n",
    "    if feature_1 == feature_2:\n",
    "        raise ValueError(\"Please select two different features.\")\n",
    "\n",
    "    # Changed to object type because of low cardinality:\n",
    "    df[\"num_major_vessels\"] = df[\"num_major_vessels\"].astype(\"object\")\n",
    "    df[\"target\"] = df[\"target\"].astype(\"object\")\n",
    "    feature_1_type = str(df[feature_1].dtype)\n",
    "    feature_2_type = str(df[feature_2].dtype)\n",
    "\n",
    "    # Dictionary to hash the appropriate function object:\n",
    "    switch_dict = {\n",
    "        (\"int64\", \"float64\"): plot_numerical_numerical, \n",
    "        (\"float64\", \"int64\"): plot_numerical_numerical,\n",
    "        (\"float64\", \"float64\"): plot_numerical_numerical,\n",
    "        (\"int64\", \"int64\"): plot_numerical_numerical,\n",
    "        (\"int64\", \"object\"): plot_numerical_categorical,\n",
    "        (\"float64\", \"object\"): plot_numerical_categorical,\n",
    "        (\"object\", \"int64\"): plot_numerical_categorical,\n",
    "        (\"object\", \"float64\"): plot_numerical_categorical,\n",
    "        (\"object\", \"object\"): plot_categorical_categorical\n",
    "    }\n",
    "\n",
    "    # Calling function object:\n",
    "    switch_dict[(feature_1_type, feature_2_type)](df, feature_1, feature_2)\n",
    "\n",
    "    return"
   ]
  },
  {
   "source": [
    "Let's test to see this works properly!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dual_features(df, \"sex\", \"num_major_vessels\")\n",
    "plot_dual_features(df, \"age\", \"cholesterol\")\n",
    "plot_dual_features(df, \"st_slope\", \"thalassemia\")"
   ]
  },
  {
   "source": [
    "## Model to predict the presence of heart disease"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "source": [
    "Here are a few things we need to do before we proceed:\n",
    "* We must dummify the categorical variables before we proceed with building the Machine  Learning model. \n",
    "* We must also ensure to remove the target variable from the rest of the data.\n",
    "* Lastly, we must change the target and the num_major_vessels to integers."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['target']\n",
    "\n",
    "# Changing back low cardinality variables to int:\n",
    "target = target.astype(int)\n",
    "df['num_major_vessels'] = df['num_major_vessels'].astype(int)\n",
    "\n",
    "# Dropping target from data:\n",
    "df.drop('target', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categorical variables into dummy variables:\n",
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting into train and test:\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, \n",
    "                                                    target, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# Checking shapes:\n",
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"X_train shape: {}\".format(X_test.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "source": [
    "### Random Forest Classiciation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Initializing Random Forest model:\n",
    "model = RandomForestClassifier(n_estimators=100, \n",
    "                               max_depth=4)\n",
    "\n",
    "# Fitting the model:\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting outcomes:\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Checking accuracy:\n",
    "print(\"Training accuracy: {}\".format(model.score(X_train, y_train)))\n",
    "print(\"Testing accuracy: {}\".format(model.score(X_test, y_test)))\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "### Sensitivity and Specificity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "total = conf_matrix.sum()\n",
    "\n",
    "# Computing sensitivity and specificity:\n",
    "sensitivity = conf_matrix[0, 0]/(conf_matrix[0, 0] + conf_matrix[1, 0])\n",
    "specificity = conf_matrix[1, 1]/(conf_matrix[1, 1] + conf_matrix[1, 0])\n",
    "\n",
    "print(\"Sensitivity: {}\".format(sensitivity))\n",
    "print(\"Specificity: {}\".format(specificity))"
   ]
  },
  {
   "source": [
    "## Saving the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We must save the model so that we can use it within our Streamlit app for making predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, \"../models/rf_model.bin\")"
   ]
  },
  {
   "source": [
    "## Next Steps"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Here I have outlined some next steps for improving the model, inference and explainability:\n",
    "* Perform more feature engineering\n",
    "* Use shap values for model explainability\n",
    "* Plot the model tree structure.\n",
    "* Check impact of each feature on the model using partial dependence and permutation importance."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Thank you for attending this workshop session! I hope all of you got to learn something new! "
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}